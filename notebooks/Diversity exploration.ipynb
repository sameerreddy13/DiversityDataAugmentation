{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3979e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "###\n",
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "###\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "###\n",
    "import spacy\n",
    "# nlp = spacy.load('en_core_web_sm', disable=[\"ner\"])\n",
    "###\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59116071",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "SAMPLE_FRAC = 0.1\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e6f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SST-2 ###\n",
    "def parse_line(line):\n",
    "    index, sent = line.split('\\t')\n",
    "    if 'sentence_index' in index:\n",
    "        return (-1,'')\n",
    "    sent = re.sub('\\n', '', sent)\n",
    "    index = int(index) - 1\n",
    "    return (index, sent)\n",
    "\n",
    "def get_original_sst2():\n",
    "    # Load SST-2\n",
    "    sst_dir = data_dir / 'SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank'\n",
    "    fp = sst_dir / 'datasetSentences.txt'\n",
    "    sents = {}\n",
    "    with fp.open('r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            index, sent = parse_line(line)\n",
    "            if not (index < 0):\n",
    "                sents[index] = sent\n",
    "    return sents\n",
    "            \n",
    "### IMDB Processing ###\n",
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ef99f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../data/.DS_Store'),\n",
       " PosixPath('../../data/SST2-Data'),\n",
       " PosixPath('../../data/IMDB Dataset.csv')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('../../data')\n",
    "list(data_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cab6f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Load IMDB data\n",
    "# df = pd.read_csv(data_dir/'IMDB Dataset.csv')\n",
    "# print(f\"Loaded {len(df)} samples, randomly sampling {int(SAMPLE_FRAC * len(df))} rows\")\n",
    "# # Sample percentage of data\n",
    "# df = df.sample(frac=SAMPLE_FRAC, random_state=SEED)\n",
    "# # Convert sentiment columns to numerical values\n",
    "# df.sentiment = df.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
    "# df['review']=df['review'].apply(denoise_text)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f69f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11855,\n",
       " \"The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load SST-2 and subsample\n",
    "sents = get_original_sst2()\n",
    "# num_samples = int(SAMPLE_FRAC * len(sents))        \n",
    "# print(f\"Got {len(sents)} samples, randomly sampling {num_samples} samples\")\n",
    "# sents = random.sample(sents, num_samples)\n",
    "len(sents), sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cf548ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize reviews\n",
    "# tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# tokenized_texts = [tokenizer(seq) for seq in df.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb6bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process reviews for sentences \n",
    "# docs = []\n",
    "# for doc in nlp.pipe(df.review):\n",
    "#     docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae52f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize SST-2 Sentences\n",
    "# tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "# sents_tokenized = [tokenizer(sent) for sent in sents]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "# sents_tokenized = list(map(word_tokenize, sents))\n",
    "# sents_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2099317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Sameer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Sameer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Sameer/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/Sameer/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "../../eda_nlp/code/eda.py:177: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  words = [word for word in words if word is not '']\n"
     ]
    }
   ],
   "source": [
    "from TextGenerationEvaluationMetrics import multiset_distances as MSD\n",
    "from DataAugmentation.data import augmentation\n",
    "from eda_nlp.code.eda import get_only_chars\n",
    "# from DataAugmentation.data import back_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inspect import getmembers, isfunction\n",
    "# print(getmembers(augmentation, isfunction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076805ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11855, 11855)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Generating eda samples:\n",
    "python eda_nlp/code/augment.py \n",
    "    --input=data/SST2-Data/SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt \n",
    "    --output=./sst2_augmented.txt \n",
    "    --num_aug=5 --alpha_sr=0.3 --alpha_rd=0.1 --alpha_ri=0.1 --alpha_rs=0.0\n",
    "'''\n",
    "def get_augmented_sst2():\n",
    "    fp = Path('../../sst2_augmented.txt')\n",
    "    sents = {}\n",
    "    with fp.open('r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            index, sent = parse_line(line)\n",
    "            if not (index < 0):\n",
    "                if index in sents:\n",
    "                    sents[index].append(sent)\n",
    "                else:\n",
    "                    sents[index] = [sent]\n",
    "    return sents\n",
    "\n",
    "orig_sents = get_original_sst2()\n",
    "orig_sents = {j:get_only_chars(t) for j, t in orig_sents.items()}\n",
    "aug_sents = get_augmented_sst2()\n",
    "len(orig_sents), len(aug_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895edd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the rock is destined to be the st century s new conan and that he s going to make a splash even greater than arnold schwarzenegger jean claud van damme or steven segal ',\n",
       " ['the shake is bound to be the st hundred s newly conan and that he s going to make a splash even great than matthew arnold schwarzenegger blue jean claud caravan damme or steven george segal',\n",
       "  'the sway is destined to be the st c s new conan and that he s live on to make believe a splash yet nifty than benedict arnold schwarzenegger jean claud new wave damme or steven george segal',\n",
       "  'the destined to be the st century s new conan and that he s going to make a splash greater than arnold schwarzenegger jean claud van damme steven segal',\n",
       "  'the rock is destined to be george segal the st century s new conan and that he s going to make a splash even matthew arnold greater than arnold schwarzenegger jean claud van damme or steven atomic number segal',\n",
       "  'the rock is destined to be the st century s new conan and that he s going to make a splash even greater than arnold atomic number schwarzenegger jean atomic number claud van damme represent or steven segal',\n",
       "  'the rock is destined to be the st century s new conan and that he s going to make a splash even greater than arnold schwarzenegger jean claud van damme or steven segal '])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_sents[0], aug_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "299b938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distances preprocess upto 5!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.0233949945593036, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "\n",
    "# ref1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'that', 'ensures', 'that', 'the', 'military', 'will', 'forever', 'heed', 'Party', 'commands']\n",
    "# ref2 = ['It', 'is', 'the', 'guiding', 'principle', 'which', 'guarantees', 'the', 'military', 'forces', 'always', 'being', 'under', 'the', 'command', 'of', 'the', 'Party']\n",
    "# ref3 = ['It', 'is', 'the', 'practical', 'guide', 'for', 'the', 'army', 'always', 'to', 'heed', 'the', 'directions', 'of', 'the', 'party']\n",
    "# sen1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'military', 'always', 'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
    "# sen2 = ['he', 'read', 'the', 'book', 'because', 'he', 'was', 'interested', 'in', 'world', 'history']\n",
    "\n",
    "references = map(word_tokenize, aug_sents[index])\n",
    "sentences = map(word_tokenize, [orig_sents[index]])\n",
    "sentences, references = map(list, (sentences, references))\n",
    "\n",
    "msd = MSD.MultisetDistances(references=references, min_n=1, max_n=5)\n",
    "msj_distance = msd.get_jaccard_score(sentences=sentences)\n",
    "msj_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e99f1e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the gorgeously elaborated continuation of the lord of the anchor ring trilogy is so brobdingnagian that a tower of words can not adequately draw co writer director tool old hickory s flesh out visual sensation of joule r r tolkien s middle ground',\n",
       " 'the gorgeously work out continuance of the lord of the reverberate trilogy is so brobdingnagian that a newspaper column of words can not adequately discover co author managing director peter andrew jackson s expanded vision of j radius radius tolkien s middle terra firma',\n",
       " 'the gorgeously elaborate continuation of the lord of the rings trilogy is so huge that a column of words can not adequately describe co writer director peter jackson s expanded vision and then of j r r tolkien immense michael joe jackson s middle earth',\n",
       " 'the gorgeously of the lord of the rings trilogy is so that a column of words can not adequately co director peter s expanded vision of j r r tolkien s middle earth',\n",
       " 'the gorgeously elaborate continuation of the lord the rings trilogy is so huge that a column of words can not adequately describe co director peter jackson s expanded vision of j r r tolkien s middle earth',\n",
       " 'the gorgeously elaborate continuation of the lord of the rings trilogy is so huge that a column of words can not adequately describe co writer director peter jackson s expanded vision of j r r tolkien s middle earth']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' '.join(s) for s in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4db50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0b2f334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'gorgeously',\n",
       " 'elaborate',\n",
       " 'continuation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lord',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rings',\n",
       " 'trilogy',\n",
       " 'is',\n",
       " 'so',\n",
       " 'huge',\n",
       " 'that',\n",
       " 'a',\n",
       " 'column',\n",
       " 'of',\n",
       " 'words',\n",
       " 'can',\n",
       " 'not',\n",
       " 'adequately',\n",
       " 'describe',\n",
       " 'co',\n",
       " 'writer',\n",
       " 'director',\n",
       " 'peter',\n",
       " 'jackson',\n",
       " 's',\n",
       " 'expanded',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'j',\n",
       " 'r',\n",
       " 'r',\n",
       " 'tolkien',\n",
       " 's',\n",
       " 'middle',\n",
       " 'earth']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc23dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dda",
   "language": "python",
   "name": "dda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
